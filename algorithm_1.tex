\documentclass{jsarticle}
\begin{document}

\title{『アルゴリズム設計マニュアル(上)』要点まとめ}
\author{ぱろすけ}
\maketitle

\setcounter{section}{-1}

\section{この文書について}
専ら自身の学習のために趣味で作成したものです。これさえ読み返せば内容が思い返せる（必要に応じて参照できる）ことを目指します。



\section{アルゴリズム設計への導入}
\textbf{挿入ソート}は、ひとつの要素から始め、まだソート済み列に加えられていない要素をひとつずつ適切な位置に挿入する。アルゴリズムの一例。

\subsection{ロボットツアーの最適化}
要するに巡回セールスマン問題。近い点に移動し続ける\textbf{最近接点}ヒューリスティックも、最も近いチェーンの端点を結んでゆく\textbf{最近接ペア}も、うまくいかない。最適解を求めるにはすべてのパターンを試す他ないが現実的な計算量ではない。

\subsection{適切な仕事の選択}
映画撮影スケジューリング問題。適切なヒューリスティックにより解ける例。

\subsection{正しさの論証}

\subsubsection{アルゴリズムの表現}
アルゴリズムは自然言語、擬似コード、プログラミング言語で表し得るが、アイディアが明確に現れるような表現法を選ぶこと。

\subsubsection{問題と性質}
一般化映画撮影スケジューリング問題には効率の良い解はない。問題を正しく形式化することが重要。定義が曖昧に過ぎたり、複雑すぎる目標を設定したりしやすい。

\subsubsection{間違いを実証する}
反例は\textbf{立証可能性}と\textbf{単純性}を持つべきである。そのためには小さな例を網羅的に考え、同点に持ち込んだり極端なものを探して弱点を見つけると良い。

\subsubsection{帰納法と再帰}
帰納法は証明に便利だよと書いているだけ。

\subsubsection{総和}
等差級数の場合、$ n $次式の和は$ n+1 $次式になる。等比級数は比が$ 1 $より小さいとき収束するが、これはアルゴリズムの解析上便利なことがある。

\subsection{問題のモデル化}
モデル化とは応用問題を厳密な形式に変換すること。

\subsubsection{組合せオブジェクト}
用語と登場シーンの説明。順列、部分集合、木、グラフ、点、多角形、文字列。きちんと定義された構造とアルゴリズムの言葉でモデル化するよう心がける。

\subsubsection{再帰的なオブジェクト}
一部を削除しても同じものである。順列、部分集合、木、グラフ、点、多角形、文字列、すべて再帰的なオブジェクトといえる。

\subsection{設計奮戦記について}

\subsection{ボクの設計奮戦記：超能力のモデル化}
モデル化を正確に行うことは大事だよという話。いきなり間違ったモデル化をされて混乱する。



\section{アルゴリズム解析}

\subsection{計算のRAMモデル}
Random Access Machine は計算量を考えるときの単純なコンピュータのモデル。メモリは無限に持つ。アルゴリズムの話ではだいたい有用。

\subsubsection{最悪、最良、そして平均の計算量}
基本的には最悪計算量だけ考えれば良い。

\subsection{ビッグオー記法}
実際の計算量はコードに依存し、グラフのでこぼこも多い。しかし実用的にはオーダーで考えれば良い。$ f(n)=O(g(n)) $は$c \cdot g(n)$ が $f(n)$ の上界であることを意味する。$ f(n)= \Omega (g(n)) $は$c \cdot g(n)$ が $f(n)$ の下界であることを意味する。$ f(n)= \Theta (g(n)) $は$c_1 \cdot g(n)$ が $f(n)$ の上界で$c_2 \cdot g(n)$ が $f(n)$ の下界であることを意味する。

\subsection{増加率と支配関係}

\subsubsection{支配関係}
よく現れるクラスと支配関係の話。特に難しい話はない。

\subsection{ビッグオーを使いこなす}
特に難しい話はない。

\subsubsection{関数の加算}
\subsubsection{関数の乗算}

\subsection{効率に関する議論}

\subsubsection{選択ソート}
選択ソートは残りの要素のうち最も小さいものをソート済み列に加える。計算量は$ \Theta(n^2)$になる。簡単。

\subsubsection{挿入ソート}
挿入ソートの計算量は$O(n^2)$になる。簡単。

\subsubsection{文字列パターンマッチング}
単純な文字列パターンマッチングについての計算量の細かな議論。落ち着けば何も難しいことはない。

\subsubsection{行列の乗算}
$3$乗のアルゴリズムであることは明らか。

\subsection{対数とその応用}
対数が現れる例をいくつか示す。

\subsubsection{対数と$2$分探索}

\subsubsection{対数と木}

\subsubsection{対数とビット}

\subsubsection{対数と乗算}
任意の$a$と$b$について$a^b=\exp(b \ln a)$と計算できる。

\subsubsection{高速な指数計算}
大きな$n$について$a^n$を計算するときは$a^n=a(a^{[n/2]} )^2$とすると高速。これは分割統治法の一種。

\subsubsection{対数と総和}
調和数について$H(n)=\sum^{n}_{i=1} 1/i \sim \ln n$が成り立つ。これは計算量の解析に使えることがある。クイックソートなど。

\subsubsection{対数と刑事裁判}
合衆国では詐欺罪の損害額と量刑は対数的な関係にある。だから一気にたくさん騙そう。

\subsection{対数の性質}
アルゴリズムの解析では、定数倍の違いにしかならないため、対数の底が何であるかは無視して良い。

\subsection{ボクの設計奮戦記：ピラミッドの謎}
ナップザック問題をスパコンで力ずくで解こうとしたけど無理だったけれど、アルゴリズムを工夫したら手元のコンピュータでも容易に解けた、という話。アルゴリズム的には『プログラミングコンテストチャレンジブック』の最初に出てきたものと酷似している。　

\subsection{高度な解析}
高度な話題であり、上巻には他に現れないが、下巻で有用であるもの。

\subsubsection{難解な関数}
逆アッカーマン関数は、きわめてゆっくり増加する関数であり、かなり大きな$n$についても$\alpha (n)<5$である。$\log n / \log \log n$は次数が$\log n$である木の高さとして現れる。

\subsubsection{極限と支配関係}
$ n! \gg c^n \gg n^3 \gg n^2 \gg n^{1+\varepsilon} \gg n \log n \gg n \gg \sqrt{n} \gg \\ \log^2 n \gg \log n \gg \log n / \log \log n \gg \log \log n \gg \alpha (n) \gg 1$



\section{データ構造}
コンテナ、辞書、優先順位付きキューについて、配列とリストでの実装を詳説する。

\subsection{連続データ構造と連結データ構造}
連続データ構造とはメモリ上で連続しているデータ構造であり、配列、行列、ヒープ、ハッシュ表などが含まれる。連結データ構造とはいくつかのメモリ領域がポインタで結ばれる構造であり、リスト、木、隣接リストなどが含まれる。

\subsubsection{配列}
配列はメモリの局所性により高速キャッシュメモリを活かすことができる。配列に対し合計$n$回の挿入を行うとして、動的配列で実現するとその総移動回数は$2n$回であるから、この計算量はなんと$O(n)$となり、静的配列の場合と等しい。

\subsubsection{ポインタと連結構造}
C言語によるリスト構造の実現の話。

\subsubsection{比較}
連結リストはメモリを食うが挿入と削除は簡単。リストも配列も再帰的なオブジェクトであることに留意すべき。

\subsection{スタックとキュー}
コンテナとはデータを内容に無関係に出し入れするデータ構造のこと。スタックでもキューでも平均待ち時間は同じ。

\subsection{辞書}
辞書の概要と、実装の違いによる基本操作の計算量の違いについて述べている。長いけれども特に難しい点はない。

\subsection{$2$分探索木}
探索が高速でかつ更新も柔軟なものの例としての$2$分探索木。ある頂点について、左部分木のすべての頂点はその頂点より小さく、右部分木のすべての頂点はその頂点より大きい。このような木は複数の形で存在し得る。

\subsubsection{$2$分探索木の実装}
木の高さを$h$とすると、ある要素の探索は$O(h)$、最小要素の探索も$O(h)$である。すべての頂点と辺を横断する際は、各頂点について左部分木、自身、右部分木の順で処理すれば良く、$O(n)$で済む。挿入については、可能な場所はただひとつであり、それは探索により見つかり、定数時間で追加を行え、$O(h)$である。削除の場合は、その頂点をその次の値で置き換えると考え、右部分木の最小値をそこに割り当てる。

\subsubsection{$2$分探索木はどれほどよいか？}
基本操作はすべて$O(h)$で行え、挿入順がランダムの場合は平均の木の高さは$O(\log n)$になる。

\subsubsection{平衡探索木}
高さが常に$O(\log n)$になる平衡探索木が提案されている。詳細についてはここでは触れられない。平衡探索木を使うことで$O(n \log n)$の様々なソートが提案される。

\subsection{優先順位付きキュー}
優先順位付きキューもいろいろな実装があるが、最小要素の位置を別に持つことでどのような実装でも定数時間で見つけることができるようになる。ただしこのときは削除に余計な時間がかかる。

\subsection{ボクの設計奮戦記：三角形を連ねる}
きちんとデータ構造を選びましょうねという話。

\subsection{ハッシングと文字列}

\subsubsection{衝突の回避}
ハッシュ値が衝突することがある。連鎖法はハッシュの各要素を隣接リストとすることで回避する。開アドレス法では、既に埋まっていた場合、その次の位置に要素を配置する。探索するときは、本来あるべき位置から連続してある要素をすべてチェックする。削除する場合は、そのあとに連続する要素をすべて再挿入する。ぐぐると、削除済みというフラグをつければ良いという記述もある。

\subsubsection{ハッシングを用いた効率的な文字列マッチング}
Rabin-Karp のアルゴリズム。部分文字列パターンマッチング問題において、テキスト文字列のすべての位置からの文字列をハッシュ化しておくことにより、ハッシュ表をチェックする問題になる。$n$文字と$m$文字のマッチングでは$O(n)$の表を構成することになり、ハッシュの計算に$O(m)$かかる。しかし、ハッシュは実は計算結果を活かして定数時間で行うことが可能である。それゆえ、だいたい$O(n+m)$時間で走らせることが可能になる。

\subsubsection{ハッシングによる重複検出}
ハッシングは、重複文書の検出や、盗作の検出、ファイルのハッシュ化による暗号化などの応用がある。ハッシングはランダム化アルゴリズムにおける基本的なアイディアで、$\Theta (n \log n)$や$\Theta (n^2)$となるような問題にも線形時間のアルゴリズムをもたらす。

\subsection{特定目的のデータ構造}
文字列にはサフィックス木とサフィックス配列があり、パターンマッチングに用いられる。幾何的データ構造にはkd木があり、高速な探索を可能にする。集合データにはビットベクトルがある。これらは下巻で詳しく述べられる。

\subsection{ボクの設計奮戦記：数珠つなぎ}
$2$分探索木で探す、ハッシュを用いる、サフィックス木、圧縮サフィックス木、と改良することで問題を解けたよという話。サフィックス木の詳細は下巻。



\section{ソートと探索}

\subsection{ソートの応用}
配列中に任意の要素kが現れる回数を知る良い方法は、配列をソートし、$k - \varepsilon$と$k + \varepsilon$の位置を探すことである。また、\textbf{凸包}を構成する良い方法は、ある軸ですべての点をソートし、その順で凸包に点を加えてゆくことである。新たな点は必ず凸包をなし、かつ削除すべき点は新たな点によって作られる領域にあるため効率が良い。ふたつの配列の共通要素を持つか判定するには小さい方をソートしたのち大きい方の各要素を探すことが考えられるが、実用的にはハッシュを用いるのが最良である。

\subsection{ソートの実際}
もとの並びの相対的な順序を崩さないものを\textbf{安定ソート}と呼ぶ。

\subsection{ヒープソート：データ構造による高速ソート}
選択ソートは素直に実装すると$O(n^2)$だが、最小要素の検索にヒープや平衡$2$分木を用いると$O(n \log n)$となる。ヒープソートは、実際のところはヒープを用いた選択ソートに過ぎない。

\subsubsection{ヒープ}
\textbf{ヒープ}は$2$分木であり、minヒープでは親は$2$つの子より小さな値を持つ。これは配列を用いることにより効率よく実現できる。ヒープの高さは常に$[ \lg n]$である。

\subsubsection{ヒープを構成する}
ヒープに要素を追加するときは、配列の空きの最初の要素に配置する。もしその値が親より小さければ親と要素を入れ替える。これは再帰的に行う。

\subsubsection{最小要素を取り出す}
最小要素は根であるから単にそれを参照すれば良い。空きはもっとも右端にある要素で埋める。もしこれが$2$つの子より大きければそれと入れ替える。これも再帰的に行う。ヒープソートは\textbf{インプレースソート}であり、ソートする要素を格納する配列以外に余分なメモリを使わない。

\subsubsection{ヒープの高速な構成法}
ひとつずつ要素を加えることでヒープを構成するのではなく、すべての要素を配置してからヒープ内を整理するほうが効率が良い。子を持つものだけ整合性をチェックすればよく、かつそのとき木は概ね低いからである。これはほぼ線形時間で済む。

ヒープの$k$番目に小さい要素が$x$以上かを判定したいとき、これを$x$より小さいものが$k$個以上かと読み替える。そして、$x$より小さい節を次々と訪問し、その数を数える。これが$k$を超えたら終了する。訪問する節の数は親と子$2$つで高々$3k$なのでこれは$O(k)$のアルゴリズムである。頭良い。

\subsubsection{逐次挿入によるソート}
挿入ソートのような方法を\textbf{逐次挿入}と呼ぶ。これもデータ構造に平衡$2$分木を用いると$O(n \log n)$で済む。

\subsection{ボクの設計奮戦記：飛行機のチケットをくれないか}
とりあえず飛行機のチケットの値段はものすごい複雑な感じになってることはわかった。

\subsection{マージソート：分割統治法によるソート}
\textbf{マージソート}はランダムアクセスに頼ることがないのが利点である。一方で、配列をソートするための補助バッファが必要となることが欠点である。部分配列はキューにコピーすると良い。

\subsection{クイックソート：ランダム化によるソート}
実装について書いてあるのでさすがに書けるようにしとくとよさそう。

\subsubsection{直観：クイックソートの平均の場合}
ランダムな$2$分探索木では$n$回の挿入の後の平均の高さは$2 \ln n$である（証明なし）。これは$1.386 \lg n$なのでそれほど高くはない。ゆえに計算量は$O(n \log n)$であるといえる。

\subsubsection{ランダム化アルゴリズム}
決定的なクイックソートのアルゴリズムでは必ず最悪の入力例が存在する。そこで、入力を予め\textbf{ランダム化}しておくことで計算量の期待値を$\Theta (n \log n)$とできる。ランダム化はサンプリングやハッシング、探索などでも用いられる。

\subsubsection{クイックソートは本当にクイック？}
適切に実装されたクイックソートはマージソートやヒープソートよりたいてい2,3倍早い、らしい。最も内側のループでの操作がより単純だから。

\subsection{分配ソート：バケットを用いたソート}
名前をソートするとき、まず頭文字別に分け、それぞれをソートすると効率的である。これを\textbf{バケットソート}あるいは\textbf{分配ソート}といい、データが均一のときに強い。実装などの細かい話はなし。

\subsubsection{ソートの下界}
ソートは$n!$の順列のそれぞれについて異なる動きをしなければならない。そのような木を考えると高さは$\Theta (n \log n)$になる。これがソートの下界である。このように自明でない下界が得られるアルゴリズムは少ない。

\subsection{ボクの設計奮戦記：スキーナの抗弁}
非常に大きなデータをソートするときはいろいろ話が違うよねという話。

\subsection{$2$分探索と関連アルゴリズム}

\subsubsection{出現の数え上げ}
ソートされた配列中で要素$k$の出現回数を求める場合、$2$分探索を改造して他の要素との境界を求めるようにすると高速に求まる。

\subsubsection{片側$2$分探索}
配列の要素数の上限がわからないとして、配列中の要素の転換点を求めたい。その場合は$A[1],A[2],A[4],A[8],...$と探索して$2$分探索の窓を決定すると早い。

\subsubsection{平方根とその他の根}
$2$分探索で平方根や方程式の解を求められるよねという話。

\subsection{分割統治法}
分割統治法は、問題を（たとえば）半分に分割しそれぞれを解く。

\subsubsection{再帰式}

\subsubsection{分割統治法の再帰式}
Strassenは$n \times n$行列の積を$n/2 \times n/2$行列の積7つに分割することにより、積を$O(n^{2.81})$で計算するアルゴリズムを得た。

\subsubsection{分割統治法の再帰式を解く}
分割統治法の再帰式$T(n)=aT(n/b)+f(n)$を簡単に解く\textbf{マスター定理}の紹介。ぐぐって使えれば良い。ここでは直感的な解釈も示されている。



\section{グラフ横断}

\subsection{グラフの特徴}
自己ループや多重辺を持つグラフを\textbf{非単純グラフ}という。非閉路な有向グラフを\textbf{DAG(Directed Acyclic Graph)}といい、スケジューリング問題などに現れる。バックトラック探索などではグラフは\textbf{明示}的には示されない。

\subsubsection{交友グラフ}
ソーシャルネットワークを題材にグラフの用語の実用例を挙げる。新しく登場する用語はグラフの\textbf{次数}で、それは頂点に接続する辺の本数を意味する。すべての頂点で次数が等しいグラフを\textbf{正則グラフ}という。

\subsection{グラフのデータ構造}
グラフは隣接行列か隣接リストで表されるが、大概は隣接リストのほうが良い。C言語による実装が示されている。実際には \it{LEDA} や \it{Boost} などのライブラリを用いると良い。

\subsection{ボクの設計奮戦記：ボクはムーアの法則の犠牲者だった}
ハードウェアの性能向上を見越したアルゴリズムを設計すると良いよねという話。

\subsection{ボクの設計奮戦記：グラフを手に入れる}
三角形の集合から\textbf{双対グラフ}を作るのに$O(n^2)$の時間をかけていたのを、改良により線形時間にした話。この場合の双対グラフとは、各三角形に対し頂点をひとつ設定し、隣接する三角形の頂点同士を結んだものをいう。データの初期化も線形でなければならない、ということが要点である。

\subsection{グラフの横断}
グラフの\textbf{横断}とは、すべての頂点を「未発見→発見済み→処理済み」と遷移させる処理である。

\subsection{幅優先探索}
キューを用いて実装する。

\subsubsection{横断を活用する}
探索する関数と頂点や辺を諸理する関数は分けておくと便利。

\subsubsection{経路の発見}
探索の途中で各頂点の親を記録しておけばそれを辿ることで最短経路を見つけることができる。

\subsection{幅優先探索の応用}

\subsubsection{連結成分}
グラフが\textbf{連結}であるとは、任意の$2$つの頂点の間に経路が存在すること。\textbf{連結成分}とはグラフの連結している部分のうち極大のもの。驚くほどたくさんの問題が連結成分を見つけたり数えたりする問題に帰着する。これは幅優先探索を複数回走らせることで実現できる。

\subsubsection{2彩色グラフ}
\textbf{$2$部グラフ}は\textbf{$2$彩色問題}を解けば見つけられる。$2$彩色問題は、頂点を見つけるたびに親と反対の色で塗り、辺を見つけるたびにその正当性をチェックすることにより解かれる。

\subsection{深さ優先探索}
深さ優先探索で頂点の出入りの時刻を記録すると、それを用いて先祖関係の発見や子孫の数のカウントを行うことができる。また、深さ優先探索は無向グラフの辺を\textbf{木辺}と\textbf{逆辺}に分類する。

\subsection{深さ優先探索の応用}
深さ優先探索では、同じ辺を2度目に訪れるとき、その辺の先は必ず直接の先祖である・

\subsubsection{閉路を見つける}
探索中に逆辺があれば、それは閉路を構成する。

\subsubsection{関節点}
削除するとグラフの連結成分が分断されるような頂点を\textbf{関節点}あるいは\textbf{切断点}という。\textbf{連結度}とはそれを削除するとグラフを非連結にするような頂点の個数をいう。

木辺と逆辺を用いて到達可能なもっとも早い先祖を保存すると、これを用いて関節点の判定ができる。自分自身までしか到達できないときその親は関節点。親までしか到達できないときその親は関節点。

1本の辺を削除するとグラフが非連結になるとき、その辺は\textbf{ブリッジ}と呼ばれる。この判定は、その辺が木辺であり、かつどの逆辺もその上下を結ばないことを確認することで行える。

\subsection{有向グラフでの深さ優先探索}
有向グラフでは、辺は\textbf{木辺}、\textbf{前進辺}、\textbf{逆辺}、\textbf{交差辺}に分類される。

\subsubsection{位相的ソート}
\textbf{位相的ソート}とは、すべての有向辺が左から右を向くように頂点を一直線に並べることである。頂点が処理済みのラベルをつけられた順序を逆にすると位相的ソートになる。

\subsubsection{強連結成分}
グラフが\textbf{強連結}であるとは、どの2つの頂点の間にも有向経路があることである。ある頂点からグラフを横断し、そして辺の方向をひっくり返したグラフについても同じように横断し、ともにすべての点に到達できればそのグラフは強連結である。閉路をすべて圧縮してひとつの点にすることにより強連結成分とそれをつなぐ辺が得られる。



\section{重み付きグラフのアルゴリズム}

\subsection{最小スパニング木}
\textbf{最小スパニング木}とは、グラフの辺の部分集合で頂点をすべて連結するもののうち、重みが最小のものをいう。

\subsubsection{プリムのアルゴリズム}
\textbf{プリムのアルゴリズム}では、木の頂点の数を増すような辺で重みが最小のものを木に加え続ける。実装の工夫により$O(nm)$から$O(m+n \ln n)$まで減らせるらしい。

\subsubsection{クラスカルのアルゴリズム}
疎なグラフで効率が良い。残ってる辺でもっとも軽いものを取り上げ、両端が同一の連結成分に入ってないければその辺を加える。連結成分の管理を\textbf{union-field}で行うことにより$O(m \log m)$で走る。

\subsubsection{union-fieldデータ構造}
union-fieldデータ構造は配列で効率よく表される。配列の各要素は親のインデックスを指し、自分自身が指定されるときそれが根であることを意味する。

\subsubsection{最小スパニング木の変種}
最大スパニング木は単にすべての辺に符号をつければ得られる。最大積スパニング木は辺の重みを対数と取り替えることにより得られる。\textbf{シュタイナー木}（重み最小化のために頂点を自由に加えて良い）と\textbf{低次数スパニング木}（頂点の最高次数を最小にする）はここでは解くことができない。

\subsection{ボクの設計奮戦記：ネットさえあればよい}
最小スパニング木を用いたクラスタリングで問題を解決した話。

\subsection{最短経路}

\subsubsection{ダイクストラのアルゴリズム}
お馴染みのダ\textbf{イクストラ法}。辺ではなく頂点にコストがあるときは、辺にコストを課すよう解釈し直すことでダイクストラ法がそのまま適用できる。

\subsubsection{全ペア最短経路}
$W[i,j]^k$を、$k$番目までの頂点を通って$i$から$j$に行くときの最小コストとする。すると$W[i,j]^k=\min(W[i,j]^{k-1},W[i,k]^{k-1}+W[k,j]^{k-1})$が成立し、これを利用して効率的に全ペア最短経路が求められる。これは$O(n^3)$ではあるがダイクストラ法を$n$回呼び出すよりは早く走る。これを\textbf{フロイド-ワーシャル法}という。

\subsubsection{推移的閉包}
最大次数の頂点を求めるときはフロイトのアルゴリズムの結果を用いれば良い。

\subsection{ボクの設計奮戦記：電話で文書を作る}
日本語入力みたいな話。

\subsection{ネットワークフローと$2$部マッチング}
\textbf{ネットワークフロー問題}とは、重み付きグラフのある頂点からある頂点まで、各パイプの最大容量（辺の重み）を守って送ることのできる最大フローを求める問題である。

\subsubsection{$2$部マッチング}
\textbf{2部グラフ}の最大マッチング問題はネットワークフロー問題として解かれる。

\subsubsection{ネットワークフローの計算}
$s$から$t$への最大フローは常に$s$-$t$最小カットの重みに等しい。残余フローグラフとは、$i$から$j$へのフローの量$f(i,j)$について、重みが$f(i,j)$の辺$(j,i)$と、重みが$c(i,j)-f(i,j)$の辺$(i,j)$を持つグラフである。残余フローグラフに$s$から$t$への経路がなくなるまでフローを増加させることによりネットワークフロー問題は解かれる。

\subsection{アルゴリズムではなくグラフの設計}
いくつかのグラフの応用例の紹介。古典的なグラフアルゴリズムが使えるように問題を解釈するとよい。



\section{組合せ探索とヒューリスティックな方法}

\subsection{バックトラック法}
\textbf{バックトラック法}は、組合せアルゴリズム問題のすべての可能な解を列挙する。バックトラック法では、深さ優先探索のような形ですべての可能な解を列挙する。解候補がベクトルで表されるとき、$k$次元の解候補をもとに$k+1$次元の解候補をつくる。

\subsubsection{すべての部分集合を構成する}
真偽値の配列を全パターン生成する例。

\subsubsection{すべての部分集合を構成する}
順列を全パターン生成する例。

\subsubsection{グラフのすべての経路を構成する}
ふつうに深さ優先探索をしているだけに見える。

\subsection{探索の枝刈り}
探索について、\textbf{枝刈り}や対称性の利用で大幅に計算量を減らせることがある。

\subsection{数独}
バックトラック法で数独を解く。解がない場合は枝刈りし、制約の多いマスを優先的に選ぶことでかなり早くなる。

\subsection{ボクの設計奮戦記：チェスボードを被覆する}
チェスボードを被覆する。枝刈りにより計算量を大幅に減らした話。

\subsection{ヒューリスティックな探索}

\subsubsection{ランダムサンプリング}
\textbf{ランダムサンプリング}、あるいは\textbf{モンテカルロ法}は、解空間からランダムにひとつを選び評価することを繰り返す。これは、解が高い確率で存在し、探索中に解に接近しているかどうか判断できない場合に有用である。

\subsubsection{局所探索}
\textbf{山登り法}について。「\textbf{排水溝に落ちた学部長}」って言葉が太字で出てくるんだけど何なのか。評価関数が凸なときや、逐次増加的な評価関数の計算が楽なときには有用である。

\subsubsection{シミュレーテッドアニーリング}
物理学を真似て組合せ最適化問題を解く。熱力学では粒子は高エネルギー状態へも遷移し得る。典型的には、コストが下がるときは必ず遷移し、コストが上がるときは$e^{-\frac{(C(s_i)-C(s_{i+1}))}{k \cdot t_i}} \geq r$のとき遷移する。ここで$t_1 = 1$、$t_k = \alpha \cdot t_{k-1}$、$0.8 \leq \alpha \leq 0.99$、$r$は$0 \leq r \leq 1$の乱数とする。これは巡回セールスマン問題をかなりうまく解く。

\subsubsection{シミュレーテッドアニーリングの応用}
グラフの最大カットの問題、独立集合を求める問題、回路基板の配置などはシミュレーテッドアニーリングにより解かれる。

\subsection{ボクの設計奮戦記：ラジオでないだけ}
ヒューリスティックを使ってビンパッキング問題の変形版を解いた話。

\subsection{ボクの設計奮戦記：配列のアニーリング}
シミュレーテッドアニーリングを応用した話。

\subsection{他のヒューリスティックな探索法}
\textbf{遺伝的アルゴリズム}、\textbf{ニューラルネットワーク}、\textbf{蟻コロニー最適化}。これらは一般に手間のわりに良い解が得られない。

\subsection{並列アルゴリズム}
安易に並列化しても大概は良いことはなく、アルゴリズム的工夫をしたほうが良いと述べている。

\subsection{ボクの設計奮戦記：速くったってどうしようもない}
並列化の負荷バランスをミスって可哀想なことになった話。



\section{動的計画法}

\subsection{キャッシング 対 計算}
\textbf{動的計画法}は本質的には記憶領域と時間とのトレードオフである。

\subsubsection{再帰によるフィボナッチ数}
再帰で書くと計算量は最低でも$1.6^n$になってしまう。

\subsubsection{キャッシングによるフィボナッチ数}
計算結果をメモしておけばフィボナッチ数は線形時間で求まる。

\subsubsection{動的計画法によるフィボナッチ数}
ここでは計算結果をすべて記憶しなくとも良いので記憶容量も定数にできる。

\subsubsection{2項係数}
2項係数$_n\mathrm{C}_x$は$_n\mathrm{C}_k = _{n-1}\mathrm{C}_{k-1} + _{n-1}\mathrm{C}_{k}$であるから動的計画法で求められる。

\subsection{近似文字列マッチング}
\textbf{近似文字列マッチング}では、スペルミスを補って与えられた文字列にもっとも近い文字列を探す。

\subsubsection{再帰による編集距離}
再帰で\textbf{編集距離}を求めることができる。間違いにコストを課し、$P$と$T$の比較について$D[i,j]$を$P_1,P_2,P_3,...,P_i$と$T_1,T_2,T_3,...,T_j$の最小コストとする。すると$D[i,j]$は、$D[i-1,j-1]$または$D[i-1,j-1]+1$（置き換え）、$D[i-1,j]+1$（挿入）、$D[i,j-1]+1$（削除）のうち最小のものとなる。

\subsubsection{動的計画法による編集距離}
上記は再帰で書くと遅いが動的計画法で書くと早い。

\subsubsection{経路の再構成}
行った操作を配列に記録しておくことで、操作の経路を容易に再構成することができる。

\subsubsection{さまざまな編集距離}
多くの問題が近似文字列マッチングの特別な場合として解かれる。\textbf{部分文字列マッチング}はゴールとするセルの指定を変えれば良い。\textbf{最長共通部分文字列}は代入を禁止すれば良い。\textbf{最大単調部分列問題}では、もとの列をソートしたものを比較対象とすれば良い。

\subsection{最長増加列}
動的計画法を設計してみる例。配列$s$の最長増加列は、終端が$s_i$の最長増加列の長さを配列として保持することにより簡単に求められる。また、それぞれについて直前要素を保持することにより再構成も可能である。

\subsection{ボクの設計奮戦記：ロブスターの進化}
動的計画法により画像のモーフィングを行う話。

\subsection{分割問題}
線形分割問題とは、与えられた整数列を、順序を変えずに各領域での合計値の最大値を最小にするように分割する問題であり、並列処理によく現れる。これは、$M[n,k]$を${s_1,s_2,s_3,...,s_n}$を$k$個の区間に分割したときの最適なコストとする。すると$M[n,k] = \min^{n}_{i=1} \max (M[i,k-1],\sum^{n}_{j=i+1} s_j)$である。

\subsection{文脈自由文法の構文解析}
\textbf{チョムスキー標準形}とは、自明でない各規則が$X \to YZ$あるいは$X \to \alpha$のどちらかで定義される文法のことをいう。任意の文脈自由文法はチョムスキー標準形に変換できる。$M[i,j,X]$を部分文字列$S[i,j]$が非終端記号$X$により生成されるとき真であるブール関数とする。すると$M[i,j,k] = \bigvee_{(X \to YX) \in G}{(\bigvee^j_{i=k}{M[i,k,Y] \cdot M[k+1,j,Z]})}$である。これを用いて動的計画法により構文解析が行える。

\subsubsection{最小重み三角分割}
よくわからない。

\subsection{動的計画法の限界：TSP}

\subsubsection{動的計画法のアルゴリズムが正しいのはどのようなときか？}
動的計画法は、現在までにどのような操作列が実行されてきたかを知る必要がない問題にのみ適する。

\subsubsection{動的計画法はどのようなときに効率がよいのか？}
動的計画法は、オブジェクトに順序がないとき、たいてい指数的な時間と記憶領域を必要とする。

\subsection{ボクの設計奮戦記：過去はただのProlog}
無理難題かと思ったら動的計画法で解けたよという話。

\subsection{ボクの設計奮戦記：バーコードのためのテキスト圧縮}
こちらも同じような話。



\section{手に負えない問題と近似アルゴリズム}
効率の良いアルゴリズムがないことを証明することについての章。どの問題が困難なのかというセンスを養うことが重要。

\subsection{問題と帰着}
問題の困難性を示すための基本となるアイディアは帰着である。

\subsubsection{鍵となるアイデア}
問題$A$が問題$B$をサブルーチンとして用いて解けるとき、問題$A$が困難ならば問題$B$も困難である。

\subsubsection{決定問題}
答えが真または偽に限られる問題を\textbf{決定問題}という。たいていの最適化問題は決定問題として表現できる。たとえば巡回セールスマン問題は「コストが$k$以下のツアーがあるか」と変換できる。

\subsection{アルゴリズムのための帰着}

\subsubsection{最近接ペア}
最近接ペアはソートを用いて解ける。もし最近接ペアの最悪計算量が$O(n \log n)$だとしたら、これはソートは$O(n \log n)$より速くできないということを意味する。

\subsubsection{最長増加部分列}
最長増加部分列問題は編集距離に帰着されるという話の繰り返し。

\subsubsection{最小公倍数}
最小公倍数$lcm(x,y)$と最大公約数$gcd(x,y)$について$lcm(x,y)=xy/gcd(x,y)$となる。

\subsubsection{凸包}
ソートは凸包を用いて解くことができる。ソートの計算量の下界は$O(n \log n)$なので、凸包を求める問題の計算量の下界も$O(n \log n)$であるといえる。

\subsection{初等的な困難性の帰着}

\subsubsection{ハミルトン閉路問題}
ハミルトン閉路問題は巡回セールスマン問題に簡単に帰着できる。

\subsubsection{独立集合問題と頂点被覆問題}
グラフ中の頂点の集合が独立であるとは、そのうち2つの頂点をつなぐ辺がないということである。頂点被覆問題で求めるべき頂点は、頂点集合から独立集合問題で求めた頂点を引いたものである。

独立集合問題は、一般化映画撮影スケジューリング問題として解くことができる。ここで、グラフの辺は2つの映画撮影のスケジュールが衝突することを表す。

\subsubsection{クリーク問題}
\textbf{クリーク}は完全部分グラフのことで、どの頂点ペアの間にも辺がある。独立集合問題は、辺と非辺の役割を逆転する補グラフ化したグラフを用意し、それにクリーク問題を適用することで解かれる。ゆえにクリーク問題は困難である。

\subsection{充足可能性問題}
節集合$C=\{ \{ v_1, \overline{v_2} \}, \{ \overline{v_1},v_2 \} \}$は$v_1=true, v_2=false$のとき真となる。一方で$C=\{ \{ v_1, v_2 \}, \{ v_1, \overline{v_2} \},\{ \overline{v_1} \} \}$にはそのような解はない。このような問題を\textbf{充足可能性問題}という。これは最悪の場合に多項時間のアルゴリズムが存在しないと考えられている。

\subsubsection{3-充足可能性問題}
節集合$C$の各節のリテラル数を3個に限定した充足可能性問題を\textbf{3-SAT}という。任意の充足可能性問題はSATに帰着することができる。1-SATや2-SATには効率的な解放があるが3-SATにはない。

\subsection{創造的な帰着}
SATと3-SATでは3-SATのほうが帰着させやすい。

\subsubsection{整数計画問題}
込み入った考察により3−SATは整数計画問題を解くことで解くことができる。

\subsubsection{頂点被覆問題}
込み入った考察により3−SATは頂点被覆問題を解くことで解くことができる。

\subsection{困難性証明のコツ}
もととなる問題にはできる限り制限をつけること。TSPではなく有向平面グラフで各頂点の次数が3のハミルトン経路を用いるなど。SATではなく3-SATや平面3-充足可能性を用いるなど。平面3-SATでは節を頂点とし同じリテラルを辺で結んだグラフで辺同士が交際しないように平面上に描くことができ、幾何的問題の困難性の証明に有用である。

目標の問題はできるだけ難しいものにすること。

もとの問題の選び方を間違わないこと。3-SAT、整数分割問題、頂点被覆問題、ハミルトン経路問題が扱いやすい。問題がグラフ問題で困難性が選択から来るとき頂点被覆問題を選び、困難性が順序から来るときはハミルトン経路問題を選ぶ。

望まないことをしたときの結果を厳しくすること（？）。

「AまたはBが選ばれるが両方が選ばれないようにすることはどうしたらいいか？」など考えること。

行き詰まったときはアルゴリズムを探すこと。

\subsection{ボクの設計奮戦記：時計との困難な戦い}
困難性証明ゲームをした話。

\subsection{ボクの設計奮戦記：その後の失敗}
困難性証明ゲームに失敗した話。

\subsection{P対NP}
\rm{P}対NPにおける主要な質問は、検証は発見より易しいのかということである。すなわち、答えが正しいかどうか調べることのほうが答えを見つけることより易しいかということである。

\subsubsection{クラスPとクラスNP}
クラス\textbf{P}とは多項式時間で解ける問題の集合である。クラス\textbf{NP}とは多項式時間で検証できる問題の集合である。明らかに$P \subseteq NP$であるが$\rm{P} = \rm{NP}$であるかは定かでない。これを\textbf{P対NP問題}という。

\subsubsection{なぜ充足可能性問題はすべての困難問題の母なのか？}
\textbf{クックの定理}は、充足可能性問題がPに入ることを証明すれば$\rm{P}=\rm{NP}$であると主張する。

\subsubsection{NP困難 対 NP完全？}
ある問題が\textbf{NP困難}であるとは、その問題がNPのどの問題とも少なくとも同じくらいに困難なときを言う。さらにその問題がNPであるとき\textbf{NP完全}であると言う。

\subsection{NP完全問題への対処}
ある問題がNP完全であるとき、対処法としては「平均の場合に速いアルゴリズムを用いる」「ヒューリスティックを用いる」「近似アルゴリズムを用いる」などの手段がある。複数を比べると良い。

\subsubsection{頂点被覆の近似}
辺を任意に選び、両端を頂点被覆に加え、辺を削除する、という手続きを繰り返すことで最適被覆の高々2倍の頂点被覆が得られる。これは最悪の場合にヒューリスティックを用いるよりずっと良い解をもたらす。

\subsubsection{ユークリッド巡回セールスマン問題}
三角不等式を満たす巡回セールスマン問題では最適ツアーの2倍以内の解を得ることができる近似アルゴリズムがある。

\subsubsection{最大非閉路部分グラフ}
辺を、左から右へ向かう集合と右から左へ向かう集合にわける。すると、大きい方の集合は非閉路で最適解の辺の少なくとも半分の辺を含む。

\subsubsection{集合被覆問題}
集合被覆問題は最適解の$\Theta (\lg n)$となる近似アルゴリズムを持つ。まだ被覆されていないものを多く含む部分集合を加えていけばよい。



\section{どのようにしてアルゴリズムを設計するか}
アルゴリズムの設計の際に確認すべき事項が数十件列挙されている。必要になったら参照すれば良いだろう。


\end{document}
